version: '2.1'

x-airflow-common:
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__DAGS_FOLDER: '/usr/local/airflow/dags'
    AIRFLOW_HOME: '/usr/local/airflow'
    EXECUTOR: 'Celery'
    LOAD_EX: 'n'
    METASTORE: 'External'
    FERNET_KEY: '81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs='
    MYSQL_HOST: '172.16.238.10'
    MYSQL_PORT: '3306'
    MYSQL_DB: 'airflowdb'
    MYSQL_USER: 'root'
    MYSQL_PASSWORD: 'mysqlrootpass007'
    MYSQL_EXTRAS: ""
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: 'mysql+mysqldb://root:mysqlrootpass007@172.16.238.10:3306/airflowdb'
    AIRFLOW__CELERY__RESULT_BACKEND: 'db+mysql://root:mysqlrootpass007@172.16.238.10:3306/airflowdb'
    AIRFLOW_ADMIN_UNAME: 'admin'
    AIRFLOW_ADMIN_PWD: 'airflowadmin007'
    environment: 'test'
    ENVIRONMENT: 'test'
    
services:
    mysqld:
        image: mysql:8.0
        restart: always
        container_name: airflow_db
        environment:
            - MYSQL_ROOT_PASSWORD=mysqlrootpass007
            - MYSQL_DATABASE=airflowdb
            - MYSQL_USER=airflow
            - MYSQL_PASSWORD=airflow
            - MYSQL_PORT=3306
        ports:
            - "3306:3306"
        expose:
            - '3306'            
        # volumes:
        #     - /data/docker/airflow-mysql:/var/lib/mysql
        networks:
            airflownetwork:
                ipv4_address: 172.16.238.10

    redis:
        image: 'redis:5.0.5'
        networks:
            - airflownetwork
        # command: redis-server --requirepass redispass

    webserver:
        build:
          context: .
          dockerfile: Dockerfile
        image: airflow-docker
        restart: always
        depends_on:
            - mysqld
            - redis
        environment:
            <<: *airflow-common-env
        volumes:
            - ./dags/:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            # - ./plugins:/usr/local/airflow/plugins
        ports:
            - "8080:8080"
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3
        networks:
            - airflownetwork
        # links:
        #     - "mysql:database"    

    flower:
        build:
          context: .
          dockerfile: Dockerfile
        image: airflow-docker
        restart: always
        depends_on:
            - mysqld
            - redis
        environment:
            <<: *airflow-common-env
        ports:
            - "5555:5555"
        command: flower
        networks:
            - airflownetwork

    scheduler:
        build:
          context: .
          dockerfile: Dockerfile
        image: airflow-docker
        restart: always
        depends_on:
            - webserver
            - mysqld
            - redis
        volumes:
            - ./dags:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            # - ./plugins:/usr/local/airflow/plugins
        environment:
            <<: *airflow-common-env
        command: scheduler
        networks:
            - airflownetwork

    worker:
        build:
          context: .
          dockerfile: Dockerfile
        image: airflow-docker
        restart: always
        depends_on:
            - scheduler
            - mysqld
            - redis
        volumes:
            - ./dags:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            # - ./plugins:/usr/local/airflow/plugins
        environment:
            <<: *airflow-common-env
        command: worker
        networks:
            - airflownetwork

networks:
  airflownetwork:
    driver: bridge
    name: airflownetwork
    ipam:
      driver: default
      config:
        - subnet: 172.16.238.0/24
          gateway: 172.16.238.1

